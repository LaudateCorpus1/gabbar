{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection - Gabbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.precision', 2)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = 5\n",
    "cv = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_training_attributes = ['changeset_id', 'changeset_harmful', 'feature_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelled_path = '../downloads/anomaly-detection/labelled/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2272, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>changeset_id</th>\n",
       "      <th>changeset_harmful</th>\n",
       "      <th>feature_id</th>\n",
       "      <th>action_create</th>\n",
       "      <th>action_modify</th>\n",
       "      <th>action_delete</th>\n",
       "      <th>geometry_type_node</th>\n",
       "      <th>geometry_type_way</th>\n",
       "      <th>geometry_type_relation</th>\n",
       "      <th>feature_version</th>\n",
       "      <th>highway_tag_deleted</th>\n",
       "      <th>highway_value_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>47332261</td>\n",
       "      <td>1</td>\n",
       "      <td>22753759</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>46038962</td>\n",
       "      <td>1</td>\n",
       "      <td>4072253881</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>47538955</td>\n",
       "      <td>1</td>\n",
       "      <td>39383065</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>47455929</td>\n",
       "      <td>1</td>\n",
       "      <td>22944171</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>47451595</td>\n",
       "      <td>1</td>\n",
       "      <td>173303722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      changeset_id  changeset_harmful  feature_id  action_create  \\\n",
       "1503      47332261                  1    22753759              0   \n",
       "2162      46038962                  1  4072253881              0   \n",
       "544       47538955                  1    39383065              0   \n",
       "1002      47455929                  1    22944171              0   \n",
       "1022      47451595                  1   173303722              0   \n",
       "\n",
       "      action_modify  action_delete  geometry_type_node  geometry_type_way  \\\n",
       "1503              1              0                   0                  1   \n",
       "2162              1              0                   1                  0   \n",
       "544               1              0                   0                  1   \n",
       "1002              1              0                   0                  1   \n",
       "1022              1              0                   0                  1   \n",
       "\n",
       "      geometry_type_relation  feature_version  highway_tag_deleted  \\\n",
       "1503                       0                5                    0   \n",
       "2162                       0                2                    0   \n",
       "544                        0                4                    0   \n",
       "1002                       0               25                    0   \n",
       "1022                       0                3                    0   \n",
       "\n",
       "      highway_value_difference  \n",
       "1503                         0  \n",
       "2162                        -9  \n",
       "544                          0  \n",
       "1002                         0  \n",
       "1022                         0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled = pd.read_csv(labelled_path + 'attributes.csv')\n",
    "print(labelled.shape)\n",
    "\n",
    "# Sort the dataset randomly.\n",
    "labelled = labelled.sample(labelled.shape[0], random_state=random_state)\n",
    "labelled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before dropping duplicates: (2272, 12)\n",
      "Shape after dropping duplicates: (2272, 12)\n"
     ]
    }
   ],
   "source": [
    "# Drop all duplicate samples.\n",
    "print('Shape before dropping duplicates: {}'.format(labelled.shape))\n",
    "labelled = labelled.drop_duplicates(subset=['changeset_id', 'feature_id'])\n",
    "print('Shape after dropping duplicates: {}'.format(labelled.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total inliers: (2217, 12)\n",
      "Total outliers: (55, 12)\n"
     ]
    }
   ],
   "source": [
    "inliers = labelled[labelled['changeset_harmful'] == 1]\n",
    "print('Total inliers: {}'.format(inliers.shape))\n",
    "\n",
    "outliers = labelled[labelled['changeset_harmful'] == -1]\n",
    "print('Total outliers: {}'.format(outliers.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset (only inliers): (1818, 12)\n",
      "Validation dataset (only inliers): (399, 12)\n",
      "Validation dataset (inliers + outliers): (454, 12)\n"
     ]
    }
   ],
   "source": [
    "total = labelled.shape[0]\n",
    "\n",
    "# 80% of the inliers will be used for training.\n",
    "training = inliers.iloc[0:round(0.8 * total)]\n",
    "training = training.reset_index(drop=True)\n",
    "print('Training dataset (only inliers): {}'.format(training.shape))\n",
    "\n",
    "# 20% of the inliers will be used for validation.\n",
    "validation = inliers.iloc[round(0.8 * total):]\n",
    "validation = validation.reset_index(drop=True)\n",
    "print('Validation dataset (only inliers): {}'.format(validation.shape))\n",
    "\n",
    "# 100% of the outliers will be used for validation too.\n",
    "validation = pd.concat([validation, outliers])\n",
    "validation = validation.reset_index(drop=True)\n",
    "print('Validation dataset (inliers + outliers): {}'.format(validation.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = training.drop(non_training_attributes, axis=1)\n",
    "y = training['changeset_harmful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(bootstrap=False, contamination=0.1, max_features=1.0,\n",
       "        max_samples='auto', n_estimators=100, n_jobs=1, random_state=None,\n",
       "        verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = IsolationForest()\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training['prediction'] = model.predict(X)\n",
    "training.to_csv(labelled_path + 'training-review.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted harmful</th>\n",
       "      <th>Predicted good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Labelled harmful</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labelled good</th>\n",
       "      <td>182</td>\n",
       "      <td>1636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted harmful  Predicted good\n",
       "Labelled harmful                  0               0\n",
       "Labelled good                   182            1636"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y, training['prediction'])\n",
    "matrix = pd.DataFrame(matrix, index=['Labelled harmful', 'Labelled good'], columns=['Predicted harmful', 'Predicted good'])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         0\n",
      "          1       1.00      0.90      0.95      1818\n",
      "\n",
      "avg / total       1.00      0.90      0.95      1818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y, training['prediction'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on training: 1.0 (0.0)\n",
      "Recall on training: 0.9 (0.03)\n",
      "F1 score on training: 0.95 (0.01)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model, X, y, cv=cv, scoring='precision')\n",
    "print('Precision on training: {} ({})'.format(round(scores.mean(), 2), round(scores.std(), 2)))\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=cv, scoring='recall')\n",
    "print('Recall on training: {} ({})'.format(round(scores.mean(), 2), round(scores.std(), 2)))\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=cv, scoring='f1')\n",
    "print('F1 score on training: {} ({})'.format(round(scores.mean(), 2), round(scores.std(), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "changeset_harmful\n",
       "-1     55\n",
       " 1    399\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.groupby('changeset_harmful').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vX = validation.drop(non_training_attributes, axis=1)\n",
    "vy = validation['changeset_harmful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation['prediction'] = model.predict(vX)\n",
    "validation.to_csv(labelled_path + 'validation-review.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted harmful</th>\n",
       "      <th>Predicted good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Labelled harmful</th>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labelled good</th>\n",
       "      <td>46</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted harmful  Predicted good\n",
       "Labelled harmful                 27              28\n",
       "Labelled good                    46             353"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(vy, validation['prediction'])\n",
    "matrix = pd.DataFrame(matrix, index=['Labelled harmful', 'Labelled good'], columns=['Predicted harmful', 'Predicted good'])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.37      0.49      0.42        55\n",
      "          1       0.93      0.88      0.91       399\n",
      "\n",
      "avg / total       0.86      0.84      0.85       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(vy, validation['prediction'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on validation: 0.88 (0.3)\n",
      "Recall on validation: 0.82 (0.28)\n",
      "F1 score on validation: 0.85 (0.29)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model, vX, vy, cv=cv, scoring='precision')\n",
    "print('Precision on validation: {} ({})'.format(round(scores.mean(), 2), round(scores.std(), 2)))\n",
    "\n",
    "scores = cross_val_score(model, vX, vy, cv=cv, scoring='recall')\n",
    "print('Recall on validation: {} ({})'.format(round(scores.mean(), 2), round(scores.std(), 2)))\n",
    "\n",
    "scores = cross_val_score(model, vX, vy, cv=cv, scoring='f1')\n",
    "print('F1 score on validation: {} ({})'.format(round(scores.mean(), 2), round(scores.std(), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unlabelled_path = testing_path = '../downloads/anomaly-detection/unlabelled/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>changeset_id</th>\n",
       "      <th>changeset_harmful</th>\n",
       "      <th>feature_id</th>\n",
       "      <th>action_create</th>\n",
       "      <th>action_modify</th>\n",
       "      <th>action_delete</th>\n",
       "      <th>geometry_type_node</th>\n",
       "      <th>geometry_type_way</th>\n",
       "      <th>geometry_type_relation</th>\n",
       "      <th>feature_version</th>\n",
       "      <th>highway_tag_deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49180736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>497516862</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49180683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30613789</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49180628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103763048</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49180608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4482158804</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49180580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374883613</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   changeset_id  changeset_harmful  feature_id  action_create  action_modify  \\\n",
       "0      49180736                NaN   497516862              0              1   \n",
       "1      49180683                NaN    30613789              0              1   \n",
       "2      49180628                NaN   103763048              0              1   \n",
       "3      49180608                NaN  4482158804              0              1   \n",
       "4      49180580                NaN   374883613              0              1   \n",
       "\n",
       "   action_delete  geometry_type_node  geometry_type_way  \\\n",
       "0              0                   0                  1   \n",
       "1              0                   0                  1   \n",
       "2              0                   0                  1   \n",
       "3              0                   1                  0   \n",
       "4              0                   0                  1   \n",
       "\n",
       "   geometry_type_relation  feature_version  highway_tag_deleted  \n",
       "0                       0                2                    0  \n",
       "1                       0                4                    0  \n",
       "2                       0               11                    0  \n",
       "3                       0                2                    0  \n",
       "4                       0                2                    0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabelled = pd.read_csv(unlabelled_path + 'attributes.csv')\n",
    "print(unlabelled.shape)\n",
    "unlabelled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before dropping duplicates: (121, 11)\n",
      "Shape after dropping duplicates: (121, 11)\n"
     ]
    }
   ],
   "source": [
    "# Drop all duplicate samples.\n",
    "print('Shape before dropping duplicates: {}'.format(unlabelled.shape))\n",
    "unlabelled = unlabelled.drop_duplicates(subset=['changeset_id', 'feature_id'])\n",
    "print('Shape after dropping duplicates: {}'.format(unlabelled.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using all of the unlabelled dataset for testing.\n",
    "testing = unlabelled.sample(unlabelled.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tX = testing.drop(non_training_attributes, axis=1)\n",
    "ty = testing['changeset_harmful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 9 and input n_features is 8 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-739cbb726ad4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtesting\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munlabelled_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'testing-review.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bkowshik/anaconda/lib/python3.5/site-packages/sklearn/ensemble/iforest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mis_inlier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mis_inlier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mis_inlier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bkowshik/anaconda/lib/python3.5/site-packages/sklearn/ensemble/iforest.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# code structure from ForestClassifier/predict_proba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bkowshik/anaconda/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    374\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 9 and input n_features is 8 "
     ]
    }
   ],
   "source": [
    "testing['prediction'] = model.predict(tX)\n",
    "testing.to_csv(unlabelled_path + 'testing-review.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tharmful_count = testing[testing['prediction'] == -1].shape[0]\n",
    "tnot_harmful_count = testing[testing['prediction'] == 1].shape[0]\n",
    "\n",
    "print('Predicted good: {}'.format(tnot_harmful_count))\n",
    "print('Predicted harmful: {}'.format(tharmful_count))\n",
    "\n",
    "print('Percentage harmful: {}%'.format(round(100.0 * tharmful_count / testing.shape[0], 2)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
